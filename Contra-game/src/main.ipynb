{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": "from rl.memory import SequentialMemory\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten\nfrom keras.optimizers import Adam\nfrom rl.agents.dqn import DQNAgent\nfrom rl.policy import BoltzmannQPolicy\nfrom rl.memory import EpisodeParameterMemory\nfrom rl.callbacks import FileLogger, ModelIntervalCheckpoint\nfrom nes_py.wrappers import JoypadSpace\nimport gym\nfrom rl.core import Processor\nfrom contra.CustomContra.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT, RIGHT_ONLY\nfrom PIL import Image\nimport argparse\nimport json\nimport matplotlib.pyplot as plt\n\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def visualize_log(filename, figsize\u003dNone, output\u003dNone):\n",
        "    with open(filename, \u0027r\u0027) as f:\n",
        "        data \u003d json.load(f)\n",
        "    if \u0027episode\u0027 not in data:\n",
        "        raise ValueError(\u0027Log file \"{}\" does not contain the \"episode\" key.\u0027.format(filename))\n",
        "    episodes \u003d data[\u0027episode\u0027]\n",
        "\n",
        "    # Get value keys. The x axis is shared and is the number of episodes.\n",
        "    keys \u003d sorted(list(set(data.keys()).difference(set([\u0027episode\u0027]))))\n",
        "\n",
        "    if figsize is None:\n",
        "        figsize \u003d (15., 5. * len(keys))\n",
        "    f, axarr \u003d plt.subplots(len(keys), sharex\u003dTrue, figsize\u003dfigsize)\n",
        "    for idx, key in enumerate(keys):\n",
        "        axarr[idx].plot(episodes, data[key])\n",
        "        axarr[idx].set_ylabel(key)\n",
        "    plt.xlabel(\u0027episodes\u0027)\n",
        "    plt.tight_layout()\n",
        "    if output is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "ENV_NAME \u003d \u0027Contra-v0\u0027\n",
        "#env \u003d gym.make(\u0027Contra-v0\u0027).env\n",
        "# access the behind-the.scenes dynamics of a specific environment\n",
        "#env \u003d env.unwrapped\n",
        "\n",
        "CUSTOM_MOVEMENT \u003d   [  [\u0027NOOP\u0027],\n",
        "    [\u0027right\u0027],\n",
        "    [\u0027right\u0027, \u0027A\u0027],\n",
        "    [\u0027right\u0027, \u0027B\u0027],\n",
        "    [\u0027right\u0027, \u0027A\u0027, \u0027up\u0027],\n",
        "    [\u0027right\u0027, \u0027B\u0027, \u0027up\u0027],\n",
        "    [\u0027right\u0027, \u0027A\u0027, \u0027B\u0027, \u0027up\u0027],\n",
        "    [\u0027A\u0027],\n",
        "    [\u0027B\u0027],\n",
        "    [\u0027A\u0027, \u0027B\u0027],\n",
        "\n",
        "    [\u0027down\u0027, \u0027A\u0027],\n",
        "    [\u0027down\u0027, \u0027B\u0027],\n",
        "    [\u0027down\u0027, \u0027A\u0027, \u0027B\u0027],\n",
        "    [\u0027up\u0027, \u0027A\u0027],\n",
        "    [\u0027up\u0027, \u0027A\u0027, \u0027B\u0027],\n",
        "]\n",
        "\n",
        "# Get the environment and extract the number of actions.\n",
        "env \u003d gym.make(ENV_NAME)\n",
        "env \u003d JoypadSpace(env, CUSTOM_MOVEMENT)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions \u003d env.action_space.n\n",
        "print(nb_actions)\n",
        "print(env.observation_space.shape)\n",
        "obs_dim \u003d env.observation_space.shape[0]\n",
        "\n",
        "\n",
        "# Next, we build a very simple model.\n",
        "model \u003d Sequential()\n",
        "model.add(Flatten(input_shape\u003d(1,) + env.observation_space.shape))\n",
        "model.add(Dense(16))\n",
        "model.add(Activation(\u0027relu\u0027))\n",
        "model.add(Dense(16))\n",
        "model.add(Activation(\u0027relu\u0027))\n",
        "model.add(Dense(16))\n",
        "model.add(Activation(\u0027relu\u0027))\n",
        "model.add(Dense(nb_actions))\n",
        "model.add(Activation(\u0027linear\u0027))\n",
        "print(model.summary())\n",
        "\n",
        "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
        "# even the metrics!\n",
        "memory \u003d SequentialMemory(limit\u003d50000, window_length\u003d1)\n",
        "policy \u003d BoltzmannQPolicy()\n",
        "dqn \u003d DQNAgent(model\u003dmodel, nb_actions\u003dnb_actions, memory\u003dmemory, nb_steps_warmup\u003d10,\n",
        "               target_model_update\u003d1e-2, policy\u003dpolicy)\n",
        "dqn.compile(Adam(lr\u003d1e-3), metrics\u003d[\u0027mae\u0027])\n",
        "\n",
        "# Okay, now it\u0027s time to learn something! We visualize the training here for show, but this\n",
        "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
        "# Ctrl + C.\n",
        "\n",
        "weights_filename \u003d \u0027/Users/swathinayak/PycharmProjects/Contra-bot/dqn_contra_weights.h5f\u0027\n",
        "checkpoint_weights_filename \u003d \u0027/Users/swathinayak/PycharmProjects/Contra-bot/dqn_contra_weights_step.h5f\u0027\n",
        "log_filename \u003d \u0027/Users/swathinayak/PycharmProjects/Contra-bot/dqn_contra_log.json\u0027\n",
        "# callbacks \u003d [ModelIntervalCheckpoint(checkpoint_weights_filename, interval\u003d250000)]\n",
        "callbacks \u003d [ModelIntervalCheckpoint(checkpoint_weights_filename, interval\u003d250)]\n",
        "callbacks +\u003d [FileLogger(log_filename, interval\u003d100)]\n",
        "# dqn.fit(env, callbacks\u003dcallbacks, nb_steps\u003d1750000, log_interval\u003d10000)\n",
        "\n",
        "dqn.fit(env, callbacks\u003dcallbacks, nb_steps\u003d50000, log_interval\u003d100, visualize\u003dTrue)\n",
        "\n",
        "\n",
        "# After training is done, we save the final weights.\n",
        "dqn.save_weights(weights_filename, overwrite\u003dTrue)\n",
        "\n",
        "parser \u003d argparse.ArgumentParser()\n",
        "parser.add_argument(\u0027filename\u0027, type\u003dstr, help\u003d\u0027The filename of the JSON log generated during training.\u0027)\n",
        "parser.add_argument(\u0027--output\u0027, type\u003dstr, default\u003dNone, help\u003d\u0027The output file. If not specified, the log will only be displayed.\u0027)\n",
        "parser.add_argument(\u0027--figsize\u0027, nargs\u003d2, type\u003dfloat, default\u003dNone, help\u003d\u0027The size of the figure in `width height` format specified in points.\u0027)\n",
        "args \u003d parser.parse_args()\n",
        "\n",
        "# You can use visualize_log to easily view the stats that were recorded during training. Simply\n",
        "# provide the filename of the `FileLogger` that was used in `FileLogger`.\n",
        "visualize_log(args.filename, output\u003dargs.output, figsize\u003dargs.figsize)\n",
        "\n",
        "\n",
        "# Finally, evaluate our algorithm for 5 episodes.\n",
        "dqn.test(env, nb_episodes\u003d5, visualize\u003dTrue)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
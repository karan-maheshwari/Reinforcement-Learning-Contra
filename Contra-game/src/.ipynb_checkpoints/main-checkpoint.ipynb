{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.memory import SequentialMemory\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from rl.agents.cem import CEMAgent\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import EpisodeParameterMemory\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym\n",
    "from rl.core import Processor\n",
    "from Contra.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT, RIGHT_ONLY\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_log(filename, figsize=None, output=None):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    if 'episode' not in data:\n",
    "        raise ValueError('Log file \"{}\" does not contain the \"episode\" key.'.format(filename))\n",
    "    episodes = data['episode']\n",
    "\n",
    "    # Get value keys. The x axis is shared and is the number of episodes.\n",
    "    keys = sorted(list(set(data.keys()).difference(set(['episode']))))\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = (15., 5. * len(keys))\n",
    "    f, axarr = plt.subplots(len(keys), sharex=True, figsize=figsize)\n",
    "    for idx, key in enumerate(keys):\n",
    "        axarr[idx].plot(episodes, data[key])\n",
    "        axarr[idx].set_ylabel(key)\n",
    "    plt.xlabel('episodes')\n",
    "    plt.tight_layout()\n",
    "    if output is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'Contra-v0'\n",
    "#env = gym.make('Contra-v0').env\n",
    "# access the behind-the.scenes dynamics of a specific environment\n",
    "#env = env.unwrapped\n",
    "\n",
    "CUSTOM_MOVEMENT =   [  ['NOOP'],\n",
    "    ['right'],\n",
    "    ['right', 'A'],\n",
    "    ['right', 'B'],\n",
    "    ['right', 'A', 'up'],\n",
    "    ['right', 'B', 'up'],\n",
    "    ['right', 'A', 'B', 'up'],\n",
    "    ['A'],\n",
    "    ['B'],\n",
    "    ['A', 'B'],\n",
    "\n",
    "    ['down', 'A'],\n",
    "    ['down', 'B'],\n",
    "    ['down', 'A', 'B'],\n",
    "    ['up', 'A'],\n",
    "    ['up', 'A', 'B'],\n",
    "]\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "env = JoypadSpace(env, CUSTOM_MOVEMENT)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "print(nb_actions)\n",
    "print(env.observation_space.shape)\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "\n",
    "weights_filename = '/Users/swathinayak/PycharmProjects/Contra-bot/dqn_contra_weights.h5f'\n",
    "checkpoint_weights_filename = '/Users/swathinayak/PycharmProjects/Contra-bot/dqn_contra_weights_step.h5f'\n",
    "log_filename = '/Users/swathinayak/PycharmProjects/Contra-bot/dqn_contra_log.json'\n",
    "# callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000)]\n",
    "callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250)]\n",
    "callbacks += [FileLogger(log_filename, interval=100)]\n",
    "# dqn.fit(env, callbacks=callbacks, nb_steps=1750000, log_interval=10000)\n",
    "\n",
    "dqn.fit(env, callbacks=callbacks, nb_steps=50000, log_interval=100, visualize=True)\n",
    "\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "dqn.save_weights(weights_filename, overwrite=True)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('filename', type=str, help='The filename of the JSON log generated during training.')\n",
    "parser.add_argument('--output', type=str, default=None, help='The output file. If not specified, the log will only be displayed.')\n",
    "parser.add_argument('--figsize', nargs=2, type=float, default=None, help='The size of the figure in `width height` format specified in points.')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# You can use visualize_log to easily view the stats that were recorded during training. Simply\n",
    "# provide the filename of the `FileLogger` that was used in `FileLogger`.\n",
    "visualize_log(args.filename, output=args.output, figsize=args.figsize)\n",
    "\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, nb_episodes=5, visualize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Contra-practice",
   "language": "python",
   "name": "contra-practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
